{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "disneyland_crowdLevel_kaggle.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbwrerDbtiE4Dz3sIkVU3K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeGitaek/Kaggle_Solving/blob/master/disneyland_crowdLevel_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5WA42sO6Ke0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "e7b21db5-d281-43d7-fd90-a6f057426562"
      },
      "source": [
        "!pip uninstall kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.6:\n",
            "  Would remove:\n",
            "    /usr/local/bin/kaggle\n",
            "    /usr/local/lib/python3.6/dist-packages/kaggle-1.5.6.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/kaggle/*\n",
            "Proceed (y/n)? ㅛ\n",
            "Your response ('ㅛ') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? \n",
            "Your response ('') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.1.1\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.4.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=10ec0f35b3114d6fde4bc74059bbb7306a5d4244865455047c4058af03ab9077\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx5Z_EEF770z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5fc949e-d865-442e-83f3-c64183f1b1ea"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!ls -lha kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 68 Jun 18 19:39 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rQtPV377_vZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ce36243e-0a14-4a6a-9c78-b692e5cf811e"
      },
      "source": [
        "!kaggle competitions download -c disneyland-crowd-levels"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading disneyland-crowd-levels.zip to /content\n",
            "\r  0% 0.00/4.15k [00:00<?, ?B/s]\n",
            "\r100% 4.15k/4.15k [00:00<00:00, 3.87MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jePfSG2E8C6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8b7bc8c6-9a39-4640-a250-4865be750996"
      },
      "source": [
        "!unzip disneyland-crowd-levels.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  disneyland-crowd-levels.zip\n",
            "  inflating: submission_sample.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3VtQH7M8H_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shCWxgOL88BI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xy = pd.read_csv('train.csv',header=None)\n",
        "scaler = MinMaxScaler()\n",
        "x_data = xy.loc[1:,1:4]\n",
        "y_data = xy.loc[1:, 7:]\n",
        "x_data=np.array(x_data, dtype=int)\n",
        "y_data=np.array(y_data, dtype=int)\n",
        "mintemp=x_data[:,0].min()\n",
        "x_data[:,0]=x_data[:,0]-mintemp\n",
        "scaler.fit(x_data)\n",
        "x_data=scaler.transform(x_data)\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.LongTensor(y_data)\n",
        "nb_class = 4\n",
        "nb_data = len(y_train)\n",
        "linear1 = torch.nn.Linear(4,100,bias=True)\n",
        "linear3 = torch.nn.Linear(100,4,bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "torch.nn.init.xavier_uniform_(linear1.weight)\n",
        "torch.nn.init.xavier_uniform_(linear3.weight)\n",
        "\n",
        "dropout = torch.nn.Dropout(p=0.5)\n",
        "model = torch.nn.Sequential(linear1,relu,dropout,\n",
        "                            linear3)"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_2oI2Mi89ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=y_train.reshape([761])\n",
        "y_train=y_train-1"
      ],
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSHLKWog9AP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42900238-1bf5-4a55-cbb8-fa21558ec6f9"
      },
      "source": [
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "op=optim.Adam(model.parameters(),lr=1e-3)\n",
        "epochs= 15000\n",
        "minloss=1000\n",
        "model=model.cuda()\n",
        "loss=loss.cuda()\n",
        "for epoch in range(epochs) : \n",
        "    rand= np.random.choice(np.array([i for i in range(761)]),761) \n",
        "    avg=[]\n",
        "    op.zero_grad()\n",
        "    output =model(x_train.cuda())\n",
        "    cost=loss(output,y_train.cuda())\n",
        "    cost.backward()\n",
        "    op.step()\n",
        "    avg.append(cost.item())\n",
        "    if np.array(avg).mean()<minloss:\n",
        "      minloss=np.array(avg).mean()\n",
        "      goodmodel=model\n",
        "    if(epoch%100==0):\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, epochs, minloss))"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/15000 Cost: 1.414204\n",
            "Epoch  100/15000 Cost: 1.180354\n",
            "Epoch  200/15000 Cost: 1.152237\n",
            "Epoch  300/15000 Cost: 1.139431\n",
            "Epoch  400/15000 Cost: 1.134808\n",
            "Epoch  500/15000 Cost: 1.132558\n",
            "Epoch  600/15000 Cost: 1.125065\n",
            "Epoch  700/15000 Cost: 1.122652\n",
            "Epoch  800/15000 Cost: 1.122652\n",
            "Epoch  900/15000 Cost: 1.120414\n",
            "Epoch 1000/15000 Cost: 1.120030\n",
            "Epoch 1100/15000 Cost: 1.115243\n",
            "Epoch 1200/15000 Cost: 1.113188\n",
            "Epoch 1300/15000 Cost: 1.111875\n",
            "Epoch 1400/15000 Cost: 1.110736\n",
            "Epoch 1500/15000 Cost: 1.110736\n",
            "Epoch 1600/15000 Cost: 1.107335\n",
            "Epoch 1700/15000 Cost: 1.104535\n",
            "Epoch 1800/15000 Cost: 1.104535\n",
            "Epoch 1900/15000 Cost: 1.104535\n",
            "Epoch 2000/15000 Cost: 1.101299\n",
            "Epoch 2100/15000 Cost: 1.101299\n",
            "Epoch 2200/15000 Cost: 1.099288\n",
            "Epoch 2300/15000 Cost: 1.099288\n",
            "Epoch 2400/15000 Cost: 1.098388\n",
            "Epoch 2500/15000 Cost: 1.098388\n",
            "Epoch 2600/15000 Cost: 1.097194\n",
            "Epoch 2700/15000 Cost: 1.097194\n",
            "Epoch 2800/15000 Cost: 1.097194\n",
            "Epoch 2900/15000 Cost: 1.097194\n",
            "Epoch 3000/15000 Cost: 1.097194\n",
            "Epoch 3100/15000 Cost: 1.097194\n",
            "Epoch 3200/15000 Cost: 1.094827\n",
            "Epoch 3300/15000 Cost: 1.092869\n",
            "Epoch 3400/15000 Cost: 1.092869\n",
            "Epoch 3500/15000 Cost: 1.092869\n",
            "Epoch 3600/15000 Cost: 1.092869\n",
            "Epoch 3700/15000 Cost: 1.092869\n",
            "Epoch 3800/15000 Cost: 1.092869\n",
            "Epoch 3900/15000 Cost: 1.092869\n",
            "Epoch 4000/15000 Cost: 1.092869\n",
            "Epoch 4100/15000 Cost: 1.092869\n",
            "Epoch 4200/15000 Cost: 1.092869\n",
            "Epoch 4300/15000 Cost: 1.092869\n",
            "Epoch 4400/15000 Cost: 1.092869\n",
            "Epoch 4500/15000 Cost: 1.092869\n",
            "Epoch 4600/15000 Cost: 1.092869\n",
            "Epoch 4700/15000 Cost: 1.092869\n",
            "Epoch 4800/15000 Cost: 1.092869\n",
            "Epoch 4900/15000 Cost: 1.091771\n",
            "Epoch 5000/15000 Cost: 1.090270\n",
            "Epoch 5100/15000 Cost: 1.090270\n",
            "Epoch 5200/15000 Cost: 1.090270\n",
            "Epoch 5300/15000 Cost: 1.087837\n",
            "Epoch 5400/15000 Cost: 1.087837\n",
            "Epoch 5500/15000 Cost: 1.087837\n",
            "Epoch 5600/15000 Cost: 1.087837\n",
            "Epoch 5700/15000 Cost: 1.087837\n",
            "Epoch 5800/15000 Cost: 1.087837\n",
            "Epoch 5900/15000 Cost: 1.087837\n",
            "Epoch 6000/15000 Cost: 1.087837\n",
            "Epoch 6100/15000 Cost: 1.087837\n",
            "Epoch 6200/15000 Cost: 1.086375\n",
            "Epoch 6300/15000 Cost: 1.086375\n",
            "Epoch 6400/15000 Cost: 1.086375\n",
            "Epoch 6500/15000 Cost: 1.086375\n",
            "Epoch 6600/15000 Cost: 1.086375\n",
            "Epoch 6700/15000 Cost: 1.086375\n",
            "Epoch 6800/15000 Cost: 1.086375\n",
            "Epoch 6900/15000 Cost: 1.086375\n",
            "Epoch 7000/15000 Cost: 1.086375\n",
            "Epoch 7100/15000 Cost: 1.086375\n",
            "Epoch 7200/15000 Cost: 1.085244\n",
            "Epoch 7300/15000 Cost: 1.085244\n",
            "Epoch 7400/15000 Cost: 1.085244\n",
            "Epoch 7500/15000 Cost: 1.084031\n",
            "Epoch 7600/15000 Cost: 1.084031\n",
            "Epoch 7700/15000 Cost: 1.084031\n",
            "Epoch 7800/15000 Cost: 1.084031\n",
            "Epoch 7900/15000 Cost: 1.082742\n",
            "Epoch 8000/15000 Cost: 1.081884\n",
            "Epoch 8100/15000 Cost: 1.081884\n",
            "Epoch 8200/15000 Cost: 1.081884\n",
            "Epoch 8300/15000 Cost: 1.081884\n",
            "Epoch 8400/15000 Cost: 1.081884\n",
            "Epoch 8500/15000 Cost: 1.081884\n",
            "Epoch 8600/15000 Cost: 1.081884\n",
            "Epoch 8700/15000 Cost: 1.078410\n",
            "Epoch 8800/15000 Cost: 1.078410\n",
            "Epoch 8900/15000 Cost: 1.078410\n",
            "Epoch 9000/15000 Cost: 1.078410\n",
            "Epoch 9100/15000 Cost: 1.078410\n",
            "Epoch 9200/15000 Cost: 1.078410\n",
            "Epoch 9300/15000 Cost: 1.078410\n",
            "Epoch 9400/15000 Cost: 1.078410\n",
            "Epoch 9500/15000 Cost: 1.078410\n",
            "Epoch 9600/15000 Cost: 1.078410\n",
            "Epoch 9700/15000 Cost: 1.073407\n",
            "Epoch 9800/15000 Cost: 1.073407\n",
            "Epoch 9900/15000 Cost: 1.073407\n",
            "Epoch 10000/15000 Cost: 1.073407\n",
            "Epoch 10100/15000 Cost: 1.073407\n",
            "Epoch 10200/15000 Cost: 1.073407\n",
            "Epoch 10300/15000 Cost: 1.073407\n",
            "Epoch 10400/15000 Cost: 1.073407\n",
            "Epoch 10500/15000 Cost: 1.073407\n",
            "Epoch 10600/15000 Cost: 1.073407\n",
            "Epoch 10700/15000 Cost: 1.073407\n",
            "Epoch 10800/15000 Cost: 1.073407\n",
            "Epoch 10900/15000 Cost: 1.073407\n",
            "Epoch 11000/15000 Cost: 1.073407\n",
            "Epoch 11100/15000 Cost: 1.073407\n",
            "Epoch 11200/15000 Cost: 1.073407\n",
            "Epoch 11300/15000 Cost: 1.073407\n",
            "Epoch 11400/15000 Cost: 1.073407\n",
            "Epoch 11500/15000 Cost: 1.073407\n",
            "Epoch 11600/15000 Cost: 1.073407\n",
            "Epoch 11700/15000 Cost: 1.073407\n",
            "Epoch 11800/15000 Cost: 1.073407\n",
            "Epoch 11900/15000 Cost: 1.073407\n",
            "Epoch 12000/15000 Cost: 1.073407\n",
            "Epoch 12100/15000 Cost: 1.073407\n",
            "Epoch 12200/15000 Cost: 1.073407\n",
            "Epoch 12300/15000 Cost: 1.073407\n",
            "Epoch 12400/15000 Cost: 1.073407\n",
            "Epoch 12500/15000 Cost: 1.073407\n",
            "Epoch 12600/15000 Cost: 1.073407\n",
            "Epoch 12700/15000 Cost: 1.073407\n",
            "Epoch 12800/15000 Cost: 1.073407\n",
            "Epoch 12900/15000 Cost: 1.073407\n",
            "Epoch 13000/15000 Cost: 1.073407\n",
            "Epoch 13100/15000 Cost: 1.073407\n",
            "Epoch 13200/15000 Cost: 1.073407\n",
            "Epoch 13300/15000 Cost: 1.073407\n",
            "Epoch 13400/15000 Cost: 1.073407\n",
            "Epoch 13500/15000 Cost: 1.073407\n",
            "Epoch 13600/15000 Cost: 1.073407\n",
            "Epoch 13700/15000 Cost: 1.073407\n",
            "Epoch 13800/15000 Cost: 1.073407\n",
            "Epoch 13900/15000 Cost: 1.073407\n",
            "Epoch 14000/15000 Cost: 1.073407\n",
            "Epoch 14100/15000 Cost: 1.073407\n",
            "Epoch 14200/15000 Cost: 1.073407\n",
            "Epoch 14300/15000 Cost: 1.073407\n",
            "Epoch 14400/15000 Cost: 1.073407\n",
            "Epoch 14500/15000 Cost: 1.073407\n",
            "Epoch 14600/15000 Cost: 1.073407\n",
            "Epoch 14700/15000 Cost: 1.073407\n",
            "Epoch 14800/15000 Cost: 1.073407\n",
            "Epoch 14900/15000 Cost: 1.073407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y24pIBH49Cm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testxy = pd.read_csv('test.csv', header=None)\n",
        "tx_data = testxy.loc[1:,1:4]\n",
        "tx_data=np.array(tx_data, dtype=int)\n",
        "tx_data[:,0]=tx_data[:,0]-mintemp\n",
        "tx_data=scaler.transform(tx_data)\n",
        "x_test = torch.FloatTensor(tx_data)"
      ],
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgGtia1t9EjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  output=goodmodel(x_test.cuda())\n",
        "  prediction = torch.argmax(output, dim=1)\n",
        "  prediction=prediction+1\n"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQFCeaZq9GCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e6f95ba-b874-4a57-8436-8e0931c5a396"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3,\n",
              "        2, 2, 2, 2, 2], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDVOmLv-9Htx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "df659337-8182-4ef0-eac9-fcd88dca43ec"
      },
      "source": [
        "submission=pd.read_csv(\"submission_sample.csv\")\n",
        "for i in range(len(prediction)):\n",
        "    submission['Crowd level'][i] = prediction[i].item()\n",
        "submission['Crowd level']=submission['Crowd level'].astype(\"int\")\n",
        "submission.to_csv(\"out.csv\",index=False,header=True)"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
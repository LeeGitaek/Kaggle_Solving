{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3XXp+DTyVwtAygPqk7pnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeGitaek/Kaggle_Solving/blob/master/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmobn_oZY3Hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "a51b1c2e-216b-4fe7-baa0-9486149d2c58"
      },
      "source": [
        "!pip uninstall --y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip  install kaggle==1.5.6\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle -v"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping kaggle as it is not installed.\u001b[0m\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 11.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.1.1\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=aaaf556d686114895f52c64ac3d988cbdb3e5a672e853615c59458eb9bf4bb40\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Kaggle API 1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQwBdr7Pa91D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6381e702-65e7-4fbc-bc99-9960642b7a7b"
      },
      "source": [
        "!kaggle competitions download -c solarenergy-meteorologicalphenomenon2\n",
        "!unzip solarenergy-meteorologicalphenomenon2.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading solarenergy-meteorologicalphenomenon2.zip to /content\n",
            "\r  0% 0.00/6.51k [00:00<?, ?B/s]\n",
            "\r100% 6.51k/6.51k [00:00<00:00, 5.87MB/s]\n",
            "Archive:  solarenergy-meteorologicalphenomenon2.zip\n",
            "  inflating: Solar_SubmitForm_2.csv  \n",
            "  inflating: Solar_TestData_2.csv    \n",
            "  inflating: Solar_TrainData_3.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHNLtsR5aIMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G1hk7U2adfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gdhjXctaqZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 1e-3\n",
        "training_epochs = 700\n",
        "batch_size = 50\n",
        "Scaler = preprocessing.StandardScaler()"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbybpT-7a5DA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "b4c5ef31-7292-4d9d-cd0a-43faaf34c290"
      },
      "source": [
        "train = pd.read_csv('Solar_TrainData_3.csv',header=None,skiprows=1,usecols=range(0,9))\n",
        "train = train.dropna()\n",
        "print(train.head(10))\n",
        "print(train.info())"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0    1    2    3      4    5     6    7      8\n",
            "0  2018-01-01  0.9  0.0  1.5  0.479  8.4  7.13  0.0  1.229\n",
            "1  2018-01-02  0.7  0.0  0.7  0.569  8.1  6.70  0.0  1.034\n",
            "2  2018-01-03  2.0  0.0  1.5  0.265  8.6  7.35  0.0  1.193\n",
            "3  2018-01-04  1.4  0.0  1.0  0.321  4.0  4.79  0.0  0.859\n",
            "4  2018-01-05  2.4  0.0  1.3  0.379  7.1  6.54  0.0  1.197\n",
            "5  2018-01-06 -0.3  0.0  0.8  0.523  8.5  7.64  0.0  1.268\n",
            "6  2018-01-07 -0.3  0.9  0.5  0.619  1.0  2.81  0.0  0.419\n",
            "7  2018-01-08  3.2  1.5  1.1  0.814  0.0  1.23  0.0  0.231\n",
            "8  2018-01-09  1.8  0.0  2.6  0.450  7.7  6.81  0.0  0.685\n",
            "9  2018-01-10 -1.7  0.5  2.3  0.573  4.3  4.31  0.0  0.640\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 350 entries, 0 to 349\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       350 non-null    object \n",
            " 1   1       350 non-null    float64\n",
            " 2   2       350 non-null    float64\n",
            " 3   3       350 non-null    float64\n",
            " 4   4       350 non-null    float64\n",
            " 5   5       350 non-null    float64\n",
            " 6   6       350 non-null    float64\n",
            " 7   7       350 non-null    float64\n",
            " 8   8       350 non-null    float64\n",
            "dtypes: float64(8), object(1)\n",
            "memory usage: 27.3+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_BxvR4VbyA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "d1b24c86-a35f-41ce-b0bc-2f9d40ef0923"
      },
      "source": [
        "test = pd.read_csv('Solar_TestData_2.csv',header=None,skiprows=1,usecols=range(0,8))\n",
        "\n",
        "print(test.head(10))\n",
        "print(test.info())"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0     1     2    3      4     5      6    7\n",
            "0  2018-01-11  -5.4   0.0  1.5  0.465   8.7   7.78  0.0\n",
            "1  2018-02-16   3.4   0.0  0.8  0.309   5.2   6.63  0.0\n",
            "2  2018-03-04   9.4  13.1  0.8  0.859   0.0   2.40  0.0\n",
            "3  2018-03-28  13.4   0.0  1.2  0.611  10.7  13.74  0.0\n",
            "4  2018-04-27  16.1   0.0  1.1  0.583  11.1  24.00  0.0\n",
            "5  2018-05-11  16.5   0.0  1.2  0.603  10.3  24.66  0.0\n",
            "6  2018-05-30  22.1   0.0  1.2  0.765   6.1  18.86  0.0\n",
            "7  2018-06-12  18.5  19.4  0.9  0.830   1.3   9.28  0.0\n",
            "8  2018-06-25  24.6   0.0  1.2  0.650  10.2  22.89  0.0\n",
            "9  2018-07-28  28.6   0.0  1.1  0.779   3.8  13.54  0.0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16 entries, 0 to 15\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       16 non-null     object \n",
            " 1   1       16 non-null     float64\n",
            " 2   2       16 non-null     float64\n",
            " 3   3       16 non-null     float64\n",
            " 4   4       16 non-null     float64\n",
            " 5   5       16 non-null     float64\n",
            " 6   6       16 non-null     float64\n",
            " 7   7       16 non-null     float64\n",
            "dtypes: float64(7), object(1)\n",
            "memory usage: 1.1+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twCYxQrlcBuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "89f4a684-b0e2-4c78-abc5-e69f56e7f267"
      },
      "source": [
        "x_train = train.iloc[:,1:7]\n",
        "y_train = train.iloc[:,[-1]]\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([350, 6])\n",
            "torch.Size([350, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZWlAfl-cinp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(x_train,y_train)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = True,\n",
        "                                          drop_last = True)\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix4gfwz_q12t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MishFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x = ctx.saved_variables[0]\n",
        "        sigmoid = torch.sigmoid(x)\n",
        "        tanh_sp = torch.tanh(F.softplus(x)) \n",
        "        return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return MishFunction.apply(x)\n",
        "\n",
        "def to_Mish(model):\n",
        "    for child_name, child in model.named_children():\n",
        "        if isinstance(child, nn.ReLU):\n",
        "            setattr(model, child_name, Mish())\n",
        "        else:\n",
        "            to_Mish(child)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHDiQ-1Cc8A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear1 = torch.nn.Linear(6,32, bias = True) # feature\n",
        "linear2 = torch.nn.Linear(32,32, bias = True)\n",
        "linear3 = torch.nn.Linear(32,32, bias = True)\n",
        "linear4 = torch.nn.Linear(32,16, bias = True)\n",
        "linear5 = torch.nn.Linear(16,16, bias = True)\n",
        "linear6 = torch.nn.Linear(16,16, bias = True)\n",
        "linear7 = torch.nn.Linear(16,8, bias = True)\n",
        "linear8 = torch.nn.Linear(8,8, bias = True)\n",
        "linear9 = torch.nn.Linear(8,8, bias = True)\n",
        "linear10 = torch.nn.Linear(8,1, bias = True)\n",
        "\n",
        "mish = Mish()"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOLT-FiqrQ1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7cd87130-1e7b-4cd2-b002-7f7311de1d7a"
      },
      "source": [
        "torch.nn.init.xavier_uniform_(linear1.weight)\n",
        "torch.nn.init.xavier_uniform_(linear2.weight)\n",
        "torch.nn.init.xavier_uniform_(linear3.weight)\n",
        "torch.nn.init.xavier_uniform_(linear4.weight)\n",
        "torch.nn.init.xavier_uniform_(linear5.weight)\n",
        "torch.nn.init.xavier_uniform_(linear6.weight)\n",
        "torch.nn.init.xavier_uniform_(linear7.weight)\n",
        "torch.nn.init.xavier_uniform_(linear8.weight)\n",
        "torch.nn.init.xavier_uniform_(linear9.weight)\n",
        "torch.nn.init.xavier_uniform_(linear10.weight)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0369, -0.1342,  0.7287,  0.6699, -0.5252, -0.4322, -0.6342,  0.2139]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7--j4OTrTPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.nn.Sequential(linear1,mish,\n",
        "                            linear2,mish,\n",
        "                            linear3,mish,\n",
        "                            linear4,mish,\n",
        "                            linear5,mish,\n",
        "                            linear6,mish,\n",
        "                            linear7,mish,\n",
        "                            linear8,mish,\n",
        "                            linear9,mish,\n",
        "                            linear10).to(device)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SbTTxt6nOYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm_LoQ4WncL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bb6a1ab-eb87-48ef-8434-51ef49414604"
      },
      "source": [
        "total_batch = len(data_loader)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    for X,Y in data_loader:\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost/total_batch\n",
        "    print('epoch ','%04d' % (epoch+1), 'cost = ','{:.9f}'.format(avg_cost))\n",
        "print('Learning finished..!')"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  0001 cost =  0.378584355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch  0002 cost =  0.135058179\n",
            "epoch  0003 cost =  0.099514894\n",
            "epoch  0004 cost =  0.067668080\n",
            "epoch  0005 cost =  0.054085888\n",
            "epoch  0006 cost =  0.046645943\n",
            "epoch  0007 cost =  0.040235478\n",
            "epoch  0008 cost =  0.038542084\n",
            "epoch  0009 cost =  0.036857985\n",
            "epoch  0010 cost =  0.035136867\n",
            "epoch  0011 cost =  0.034404941\n",
            "epoch  0012 cost =  0.033738114\n",
            "epoch  0013 cost =  0.033007637\n",
            "epoch  0014 cost =  0.032711986\n",
            "epoch  0015 cost =  0.031921394\n",
            "epoch  0016 cost =  0.031626508\n",
            "epoch  0017 cost =  0.031127226\n",
            "epoch  0018 cost =  0.031153090\n",
            "epoch  0019 cost =  0.030485118\n",
            "epoch  0020 cost =  0.029813968\n",
            "epoch  0021 cost =  0.029740391\n",
            "epoch  0022 cost =  0.029831180\n",
            "epoch  0023 cost =  0.028933706\n",
            "epoch  0024 cost =  0.028564265\n",
            "epoch  0025 cost =  0.028284272\n",
            "epoch  0026 cost =  0.027589813\n",
            "epoch  0027 cost =  0.027565092\n",
            "epoch  0028 cost =  0.028020458\n",
            "epoch  0029 cost =  0.027725045\n",
            "epoch  0030 cost =  0.027876455\n",
            "epoch  0031 cost =  0.026376270\n",
            "epoch  0032 cost =  0.025575707\n",
            "epoch  0033 cost =  0.025249204\n",
            "epoch  0034 cost =  0.024465203\n",
            "epoch  0035 cost =  0.024515767\n",
            "epoch  0036 cost =  0.024237417\n",
            "epoch  0037 cost =  0.023325574\n",
            "epoch  0038 cost =  0.022912350\n",
            "epoch  0039 cost =  0.022761034\n",
            "epoch  0040 cost =  0.022689423\n",
            "epoch  0041 cost =  0.021328669\n",
            "epoch  0042 cost =  0.021326428\n",
            "epoch  0043 cost =  0.020621302\n",
            "epoch  0044 cost =  0.020159142\n",
            "epoch  0045 cost =  0.019871142\n",
            "epoch  0046 cost =  0.019208707\n",
            "epoch  0047 cost =  0.018849397\n",
            "epoch  0048 cost =  0.018423483\n",
            "epoch  0049 cost =  0.017530628\n",
            "epoch  0050 cost =  0.017307289\n",
            "epoch  0051 cost =  0.018214028\n",
            "epoch  0052 cost =  0.016191483\n",
            "epoch  0053 cost =  0.018180236\n",
            "epoch  0054 cost =  0.016280701\n",
            "epoch  0055 cost =  0.015386201\n",
            "epoch  0056 cost =  0.015248471\n",
            "epoch  0057 cost =  0.014474929\n",
            "epoch  0058 cost =  0.014515232\n",
            "epoch  0059 cost =  0.014122546\n",
            "epoch  0060 cost =  0.013829323\n",
            "epoch  0061 cost =  0.013798599\n",
            "epoch  0062 cost =  0.013412333\n",
            "epoch  0063 cost =  0.013303574\n",
            "epoch  0064 cost =  0.013317036\n",
            "epoch  0065 cost =  0.012524214\n",
            "epoch  0066 cost =  0.012536242\n",
            "epoch  0067 cost =  0.014388783\n",
            "epoch  0068 cost =  0.013014779\n",
            "epoch  0069 cost =  0.012507302\n",
            "epoch  0070 cost =  0.012914996\n",
            "epoch  0071 cost =  0.011955895\n",
            "epoch  0072 cost =  0.011628713\n",
            "epoch  0073 cost =  0.011652206\n",
            "epoch  0074 cost =  0.011638557\n",
            "epoch  0075 cost =  0.012750063\n",
            "epoch  0076 cost =  0.011935764\n",
            "epoch  0077 cost =  0.011531987\n",
            "epoch  0078 cost =  0.011252429\n",
            "epoch  0079 cost =  0.011311051\n",
            "epoch  0080 cost =  0.010907410\n",
            "epoch  0081 cost =  0.011017073\n",
            "epoch  0082 cost =  0.012568636\n",
            "epoch  0083 cost =  0.013896842\n",
            "epoch  0084 cost =  0.013245369\n",
            "epoch  0085 cost =  0.013087992\n",
            "epoch  0086 cost =  0.011504976\n",
            "epoch  0087 cost =  0.013604958\n",
            "epoch  0088 cost =  0.011902295\n",
            "epoch  0089 cost =  0.010890188\n",
            "epoch  0090 cost =  0.011031586\n",
            "epoch  0091 cost =  0.011064021\n",
            "epoch  0092 cost =  0.010589764\n",
            "epoch  0093 cost =  0.010698219\n",
            "epoch  0094 cost =  0.010182225\n",
            "epoch  0095 cost =  0.010339628\n",
            "epoch  0096 cost =  0.011233939\n",
            "epoch  0097 cost =  0.011668932\n",
            "epoch  0098 cost =  0.010319158\n",
            "epoch  0099 cost =  0.010107592\n",
            "epoch  0100 cost =  0.010256597\n",
            "epoch  0101 cost =  0.010618476\n",
            "epoch  0102 cost =  0.010730571\n",
            "epoch  0103 cost =  0.009694574\n",
            "epoch  0104 cost =  0.009916996\n",
            "epoch  0105 cost =  0.009934909\n",
            "epoch  0106 cost =  0.009441868\n",
            "epoch  0107 cost =  0.010966952\n",
            "epoch  0108 cost =  0.011071904\n",
            "epoch  0109 cost =  0.011109837\n",
            "epoch  0110 cost =  0.011493135\n",
            "epoch  0111 cost =  0.010101872\n",
            "epoch  0112 cost =  0.009406392\n",
            "epoch  0113 cost =  0.009472438\n",
            "epoch  0114 cost =  0.009665880\n",
            "epoch  0115 cost =  0.009534238\n",
            "epoch  0116 cost =  0.009421546\n",
            "epoch  0117 cost =  0.009876044\n",
            "epoch  0118 cost =  0.009899485\n",
            "epoch  0119 cost =  0.009857669\n",
            "epoch  0120 cost =  0.009913492\n",
            "epoch  0121 cost =  0.009104725\n",
            "epoch  0122 cost =  0.009529551\n",
            "epoch  0123 cost =  0.009337701\n",
            "epoch  0124 cost =  0.009239364\n",
            "epoch  0125 cost =  0.009454155\n",
            "epoch  0126 cost =  0.009041355\n",
            "epoch  0127 cost =  0.010271221\n",
            "epoch  0128 cost =  0.009925504\n",
            "epoch  0129 cost =  0.009659684\n",
            "epoch  0130 cost =  0.009837588\n",
            "epoch  0131 cost =  0.009288164\n",
            "epoch  0132 cost =  0.009492431\n",
            "epoch  0133 cost =  0.009197325\n",
            "epoch  0134 cost =  0.008431764\n",
            "epoch  0135 cost =  0.008517134\n",
            "epoch  0136 cost =  0.009053203\n",
            "epoch  0137 cost =  0.009719593\n",
            "epoch  0138 cost =  0.009773375\n",
            "epoch  0139 cost =  0.008789422\n",
            "epoch  0140 cost =  0.009104215\n",
            "epoch  0141 cost =  0.010745769\n",
            "epoch  0142 cost =  0.010578085\n",
            "epoch  0143 cost =  0.010024472\n",
            "epoch  0144 cost =  0.009275288\n",
            "epoch  0145 cost =  0.008274756\n",
            "epoch  0146 cost =  0.008575585\n",
            "epoch  0147 cost =  0.008447023\n",
            "epoch  0148 cost =  0.008759454\n",
            "epoch  0149 cost =  0.008526627\n",
            "epoch  0150 cost =  0.008411436\n",
            "epoch  0151 cost =  0.008686231\n",
            "epoch  0152 cost =  0.008557952\n",
            "epoch  0153 cost =  0.008348650\n",
            "epoch  0154 cost =  0.008231487\n",
            "epoch  0155 cost =  0.009366707\n",
            "epoch  0156 cost =  0.008418093\n",
            "epoch  0157 cost =  0.008028203\n",
            "epoch  0158 cost =  0.008423050\n",
            "epoch  0159 cost =  0.008786683\n",
            "epoch  0160 cost =  0.010070337\n",
            "epoch  0161 cost =  0.008757045\n",
            "epoch  0162 cost =  0.008874486\n",
            "epoch  0163 cost =  0.008570970\n",
            "epoch  0164 cost =  0.008230351\n",
            "epoch  0165 cost =  0.008495975\n",
            "epoch  0166 cost =  0.008572658\n",
            "epoch  0167 cost =  0.008188921\n",
            "epoch  0168 cost =  0.008793641\n",
            "epoch  0169 cost =  0.009172905\n",
            "epoch  0170 cost =  0.011073509\n",
            "epoch  0171 cost =  0.011288780\n",
            "epoch  0172 cost =  0.009502157\n",
            "epoch  0173 cost =  0.009085943\n",
            "epoch  0174 cost =  0.008842819\n",
            "epoch  0175 cost =  0.008545531\n",
            "epoch  0176 cost =  0.009925891\n",
            "epoch  0177 cost =  0.009967840\n",
            "epoch  0178 cost =  0.008811151\n",
            "epoch  0179 cost =  0.008634108\n",
            "epoch  0180 cost =  0.007784689\n",
            "epoch  0181 cost =  0.008182528\n",
            "epoch  0182 cost =  0.008035025\n",
            "epoch  0183 cost =  0.007602246\n",
            "epoch  0184 cost =  0.008019909\n",
            "epoch  0185 cost =  0.007527214\n",
            "epoch  0186 cost =  0.007785773\n",
            "epoch  0187 cost =  0.007790428\n",
            "epoch  0188 cost =  0.007918837\n",
            "epoch  0189 cost =  0.008145486\n",
            "epoch  0190 cost =  0.007781970\n",
            "epoch  0191 cost =  0.008421509\n",
            "epoch  0192 cost =  0.007638961\n",
            "epoch  0193 cost =  0.007686992\n",
            "epoch  0194 cost =  0.007765456\n",
            "epoch  0195 cost =  0.007342828\n",
            "epoch  0196 cost =  0.008077582\n",
            "epoch  0197 cost =  0.008382702\n",
            "epoch  0198 cost =  0.008448818\n",
            "epoch  0199 cost =  0.007857802\n",
            "epoch  0200 cost =  0.007841561\n",
            "epoch  0201 cost =  0.007589335\n",
            "epoch  0202 cost =  0.007116914\n",
            "epoch  0203 cost =  0.007585156\n",
            "epoch  0204 cost =  0.007692236\n",
            "epoch  0205 cost =  0.008021644\n",
            "epoch  0206 cost =  0.008214943\n",
            "epoch  0207 cost =  0.008220289\n",
            "epoch  0208 cost =  0.007645046\n",
            "epoch  0209 cost =  0.007669239\n",
            "epoch  0210 cost =  0.007111732\n",
            "epoch  0211 cost =  0.007121794\n",
            "epoch  0212 cost =  0.007268464\n",
            "epoch  0213 cost =  0.007186235\n",
            "epoch  0214 cost =  0.007911494\n",
            "epoch  0215 cost =  0.008090950\n",
            "epoch  0216 cost =  0.009182659\n",
            "epoch  0217 cost =  0.010288042\n",
            "epoch  0218 cost =  0.008535201\n",
            "epoch  0219 cost =  0.007618690\n",
            "epoch  0220 cost =  0.007159894\n",
            "epoch  0221 cost =  0.007307267\n",
            "epoch  0222 cost =  0.007374087\n",
            "epoch  0223 cost =  0.007422441\n",
            "epoch  0224 cost =  0.007705129\n",
            "epoch  0225 cost =  0.007891891\n",
            "epoch  0226 cost =  0.007363250\n",
            "epoch  0227 cost =  0.007664057\n",
            "epoch  0228 cost =  0.007820564\n",
            "epoch  0229 cost =  0.008149197\n",
            "epoch  0230 cost =  0.007806183\n",
            "epoch  0231 cost =  0.008872330\n",
            "epoch  0232 cost =  0.007016622\n",
            "epoch  0233 cost =  0.007242340\n",
            "epoch  0234 cost =  0.007168787\n",
            "epoch  0235 cost =  0.006874189\n",
            "epoch  0236 cost =  0.007349937\n",
            "epoch  0237 cost =  0.008886601\n",
            "epoch  0238 cost =  0.007997705\n",
            "epoch  0239 cost =  0.007486360\n",
            "epoch  0240 cost =  0.007322102\n",
            "epoch  0241 cost =  0.007035814\n",
            "epoch  0242 cost =  0.007539440\n",
            "epoch  0243 cost =  0.006865888\n",
            "epoch  0244 cost =  0.006864388\n",
            "epoch  0245 cost =  0.006785010\n",
            "epoch  0246 cost =  0.006781477\n",
            "epoch  0247 cost =  0.006931461\n",
            "epoch  0248 cost =  0.007952811\n",
            "epoch  0249 cost =  0.008526041\n",
            "epoch  0250 cost =  0.008114688\n",
            "epoch  0251 cost =  0.006858524\n",
            "epoch  0252 cost =  0.007974639\n",
            "epoch  0253 cost =  0.009106817\n",
            "epoch  0254 cost =  0.009274061\n",
            "epoch  0255 cost =  0.007191939\n",
            "epoch  0256 cost =  0.007090761\n",
            "epoch  0257 cost =  0.008100769\n",
            "epoch  0258 cost =  0.007887427\n",
            "epoch  0259 cost =  0.007569719\n",
            "epoch  0260 cost =  0.007030110\n",
            "epoch  0261 cost =  0.006821512\n",
            "epoch  0262 cost =  0.007261829\n",
            "epoch  0263 cost =  0.008573937\n",
            "epoch  0264 cost =  0.007698678\n",
            "epoch  0265 cost =  0.008585401\n",
            "epoch  0266 cost =  0.007313777\n",
            "epoch  0267 cost =  0.006990901\n",
            "epoch  0268 cost =  0.007341627\n",
            "epoch  0269 cost =  0.007808581\n",
            "epoch  0270 cost =  0.007356901\n",
            "epoch  0271 cost =  0.006791731\n",
            "epoch  0272 cost =  0.006680183\n",
            "epoch  0273 cost =  0.006403568\n",
            "epoch  0274 cost =  0.007477290\n",
            "epoch  0275 cost =  0.008144102\n",
            "epoch  0276 cost =  0.007914692\n",
            "epoch  0277 cost =  0.008005058\n",
            "epoch  0278 cost =  0.007731350\n",
            "epoch  0279 cost =  0.007434980\n",
            "epoch  0280 cost =  0.006924726\n",
            "epoch  0281 cost =  0.007303445\n",
            "epoch  0282 cost =  0.007064570\n",
            "epoch  0283 cost =  0.006466593\n",
            "epoch  0284 cost =  0.006487838\n",
            "epoch  0285 cost =  0.006543743\n",
            "epoch  0286 cost =  0.006301561\n",
            "epoch  0287 cost =  0.006291034\n",
            "epoch  0288 cost =  0.006215099\n",
            "epoch  0289 cost =  0.006087396\n",
            "epoch  0290 cost =  0.006723739\n",
            "epoch  0291 cost =  0.008594532\n",
            "epoch  0292 cost =  0.007447417\n",
            "epoch  0293 cost =  0.006201313\n",
            "epoch  0294 cost =  0.006664829\n",
            "epoch  0295 cost =  0.006680777\n",
            "epoch  0296 cost =  0.006409937\n",
            "epoch  0297 cost =  0.006069928\n",
            "epoch  0298 cost =  0.006057949\n",
            "epoch  0299 cost =  0.006255555\n",
            "epoch  0300 cost =  0.006153607\n",
            "epoch  0301 cost =  0.006289540\n",
            "epoch  0302 cost =  0.006943560\n",
            "epoch  0303 cost =  0.006344903\n",
            "epoch  0304 cost =  0.006821873\n",
            "epoch  0305 cost =  0.008133793\n",
            "epoch  0306 cost =  0.008922852\n",
            "epoch  0307 cost =  0.006684308\n",
            "epoch  0308 cost =  0.008268465\n",
            "epoch  0309 cost =  0.008172211\n",
            "epoch  0310 cost =  0.008373257\n",
            "epoch  0311 cost =  0.008288399\n",
            "epoch  0312 cost =  0.007056357\n",
            "epoch  0313 cost =  0.006745866\n",
            "epoch  0314 cost =  0.006888042\n",
            "epoch  0315 cost =  0.006628055\n",
            "epoch  0316 cost =  0.006806450\n",
            "epoch  0317 cost =  0.006109355\n",
            "epoch  0318 cost =  0.006686402\n",
            "epoch  0319 cost =  0.007191776\n",
            "epoch  0320 cost =  0.006937401\n",
            "epoch  0321 cost =  0.008894205\n",
            "epoch  0322 cost =  0.007933950\n",
            "epoch  0323 cost =  0.006230666\n",
            "epoch  0324 cost =  0.006601362\n",
            "epoch  0325 cost =  0.005876208\n",
            "epoch  0326 cost =  0.005702564\n",
            "epoch  0327 cost =  0.005575234\n",
            "epoch  0328 cost =  0.006046135\n",
            "epoch  0329 cost =  0.006210918\n",
            "epoch  0330 cost =  0.007227171\n",
            "epoch  0331 cost =  0.007561238\n",
            "epoch  0332 cost =  0.006778430\n",
            "epoch  0333 cost =  0.005684691\n",
            "epoch  0334 cost =  0.005929139\n",
            "epoch  0335 cost =  0.006006367\n",
            "epoch  0336 cost =  0.006352267\n",
            "epoch  0337 cost =  0.005835278\n",
            "epoch  0338 cost =  0.006481360\n",
            "epoch  0339 cost =  0.006409449\n",
            "epoch  0340 cost =  0.005698005\n",
            "epoch  0341 cost =  0.005743974\n",
            "epoch  0342 cost =  0.005817450\n",
            "epoch  0343 cost =  0.006473284\n",
            "epoch  0344 cost =  0.006265889\n",
            "epoch  0345 cost =  0.005843998\n",
            "epoch  0346 cost =  0.006545730\n",
            "epoch  0347 cost =  0.006858516\n",
            "epoch  0348 cost =  0.005829881\n",
            "epoch  0349 cost =  0.005504053\n",
            "epoch  0350 cost =  0.006202137\n",
            "epoch  0351 cost =  0.006186716\n",
            "epoch  0352 cost =  0.006284911\n",
            "epoch  0353 cost =  0.005839157\n",
            "epoch  0354 cost =  0.005813009\n",
            "epoch  0355 cost =  0.005837704\n",
            "epoch  0356 cost =  0.006340764\n",
            "epoch  0357 cost =  0.006975303\n",
            "epoch  0358 cost =  0.006534181\n",
            "epoch  0359 cost =  0.007402761\n",
            "epoch  0360 cost =  0.005803437\n",
            "epoch  0361 cost =  0.007357941\n",
            "epoch  0362 cost =  0.006061196\n",
            "epoch  0363 cost =  0.005840662\n",
            "epoch  0364 cost =  0.006045240\n",
            "epoch  0365 cost =  0.005713331\n",
            "epoch  0366 cost =  0.006158981\n",
            "epoch  0367 cost =  0.005434012\n",
            "epoch  0368 cost =  0.005450544\n",
            "epoch  0369 cost =  0.005564496\n",
            "epoch  0370 cost =  0.005366903\n",
            "epoch  0371 cost =  0.005532766\n",
            "epoch  0372 cost =  0.006189792\n",
            "epoch  0373 cost =  0.005691445\n",
            "epoch  0374 cost =  0.005965716\n",
            "epoch  0375 cost =  0.005900828\n",
            "epoch  0376 cost =  0.005634158\n",
            "epoch  0377 cost =  0.005332736\n",
            "epoch  0378 cost =  0.005310107\n",
            "epoch  0379 cost =  0.005280435\n",
            "epoch  0380 cost =  0.005489399\n",
            "epoch  0381 cost =  0.005893601\n",
            "epoch  0382 cost =  0.006521250\n",
            "epoch  0383 cost =  0.006355778\n",
            "epoch  0384 cost =  0.005999337\n",
            "epoch  0385 cost =  0.005704797\n",
            "epoch  0386 cost =  0.006818196\n",
            "epoch  0387 cost =  0.007380331\n",
            "epoch  0388 cost =  0.007433415\n",
            "epoch  0389 cost =  0.006668892\n",
            "epoch  0390 cost =  0.005267104\n",
            "epoch  0391 cost =  0.005486500\n",
            "epoch  0392 cost =  0.007210275\n",
            "epoch  0393 cost =  0.006039018\n",
            "epoch  0394 cost =  0.005678080\n",
            "epoch  0395 cost =  0.006167471\n",
            "epoch  0396 cost =  0.005138746\n",
            "epoch  0397 cost =  0.005411573\n",
            "epoch  0398 cost =  0.005349384\n",
            "epoch  0399 cost =  0.005787341\n",
            "epoch  0400 cost =  0.006529626\n",
            "epoch  0401 cost =  0.005250375\n",
            "epoch  0402 cost =  0.005052780\n",
            "epoch  0403 cost =  0.005247945\n",
            "epoch  0404 cost =  0.005313244\n",
            "epoch  0405 cost =  0.005311875\n",
            "epoch  0406 cost =  0.005370920\n",
            "epoch  0407 cost =  0.005602139\n",
            "epoch  0408 cost =  0.005565009\n",
            "epoch  0409 cost =  0.005382455\n",
            "epoch  0410 cost =  0.005871089\n",
            "epoch  0411 cost =  0.005183191\n",
            "epoch  0412 cost =  0.005412964\n",
            "epoch  0413 cost =  0.005346613\n",
            "epoch  0414 cost =  0.004840835\n",
            "epoch  0415 cost =  0.005296277\n",
            "epoch  0416 cost =  0.005129419\n",
            "epoch  0417 cost =  0.005759731\n",
            "epoch  0418 cost =  0.006079544\n",
            "epoch  0419 cost =  0.005663774\n",
            "epoch  0420 cost =  0.005175354\n",
            "epoch  0421 cost =  0.005155759\n",
            "epoch  0422 cost =  0.005049494\n",
            "epoch  0423 cost =  0.005066317\n",
            "epoch  0424 cost =  0.004826816\n",
            "epoch  0425 cost =  0.004912470\n",
            "epoch  0426 cost =  0.005004414\n",
            "epoch  0427 cost =  0.005003572\n",
            "epoch  0428 cost =  0.005334513\n",
            "epoch  0429 cost =  0.006132812\n",
            "epoch  0430 cost =  0.005629355\n",
            "epoch  0431 cost =  0.005599766\n",
            "epoch  0432 cost =  0.005030425\n",
            "epoch  0433 cost =  0.005163023\n",
            "epoch  0434 cost =  0.004992592\n",
            "epoch  0435 cost =  0.004986002\n",
            "epoch  0436 cost =  0.004794914\n",
            "epoch  0437 cost =  0.004929395\n",
            "epoch  0438 cost =  0.005038133\n",
            "epoch  0439 cost =  0.005045393\n",
            "epoch  0440 cost =  0.004855390\n",
            "epoch  0441 cost =  0.005058818\n",
            "epoch  0442 cost =  0.005629382\n",
            "epoch  0443 cost =  0.005362518\n",
            "epoch  0444 cost =  0.006261791\n",
            "epoch  0445 cost =  0.006539221\n",
            "epoch  0446 cost =  0.005707001\n",
            "epoch  0447 cost =  0.005545584\n",
            "epoch  0448 cost =  0.005379187\n",
            "epoch  0449 cost =  0.005845467\n",
            "epoch  0450 cost =  0.005426182\n",
            "epoch  0451 cost =  0.005012465\n",
            "epoch  0452 cost =  0.005031759\n",
            "epoch  0453 cost =  0.005197810\n",
            "epoch  0454 cost =  0.004913338\n",
            "epoch  0455 cost =  0.004915674\n",
            "epoch  0456 cost =  0.004919664\n",
            "epoch  0457 cost =  0.004806771\n",
            "epoch  0458 cost =  0.005055877\n",
            "epoch  0459 cost =  0.004823949\n",
            "epoch  0460 cost =  0.005261460\n",
            "epoch  0461 cost =  0.004932119\n",
            "epoch  0462 cost =  0.004664370\n",
            "epoch  0463 cost =  0.004865899\n",
            "epoch  0464 cost =  0.005074666\n",
            "epoch  0465 cost =  0.005038380\n",
            "epoch  0466 cost =  0.004987342\n",
            "epoch  0467 cost =  0.005460891\n",
            "epoch  0468 cost =  0.005421909\n",
            "epoch  0469 cost =  0.005389591\n",
            "epoch  0470 cost =  0.004895167\n",
            "epoch  0471 cost =  0.005219646\n",
            "epoch  0472 cost =  0.004625021\n",
            "epoch  0473 cost =  0.004546274\n",
            "epoch  0474 cost =  0.004732142\n",
            "epoch  0475 cost =  0.004753943\n",
            "epoch  0476 cost =  0.005492015\n",
            "epoch  0477 cost =  0.004874776\n",
            "epoch  0478 cost =  0.005674341\n",
            "epoch  0479 cost =  0.005426068\n",
            "epoch  0480 cost =  0.004611203\n",
            "epoch  0481 cost =  0.004902112\n",
            "epoch  0482 cost =  0.005164503\n",
            "epoch  0483 cost =  0.004928131\n",
            "epoch  0484 cost =  0.004548651\n",
            "epoch  0485 cost =  0.005017894\n",
            "epoch  0486 cost =  0.005587237\n",
            "epoch  0487 cost =  0.005414202\n",
            "epoch  0488 cost =  0.004896190\n",
            "epoch  0489 cost =  0.005190322\n",
            "epoch  0490 cost =  0.004704508\n",
            "epoch  0491 cost =  0.005342590\n",
            "epoch  0492 cost =  0.006215406\n",
            "epoch  0493 cost =  0.006255184\n",
            "epoch  0494 cost =  0.006127337\n",
            "epoch  0495 cost =  0.006030690\n",
            "epoch  0496 cost =  0.005507574\n",
            "epoch  0497 cost =  0.005190611\n",
            "epoch  0498 cost =  0.005221118\n",
            "epoch  0499 cost =  0.004931306\n",
            "epoch  0500 cost =  0.004474239\n",
            "epoch  0501 cost =  0.004577307\n",
            "epoch  0502 cost =  0.004509374\n",
            "epoch  0503 cost =  0.004334546\n",
            "epoch  0504 cost =  0.004566913\n",
            "epoch  0505 cost =  0.004641605\n",
            "epoch  0506 cost =  0.004655543\n",
            "epoch  0507 cost =  0.004576837\n",
            "epoch  0508 cost =  0.004716040\n",
            "epoch  0509 cost =  0.004691478\n",
            "epoch  0510 cost =  0.004462824\n",
            "epoch  0511 cost =  0.004422801\n",
            "epoch  0512 cost =  0.004897061\n",
            "epoch  0513 cost =  0.004576043\n",
            "epoch  0514 cost =  0.004733194\n",
            "epoch  0515 cost =  0.004302283\n",
            "epoch  0516 cost =  0.004212727\n",
            "epoch  0517 cost =  0.004550597\n",
            "epoch  0518 cost =  0.004666089\n",
            "epoch  0519 cost =  0.004837221\n",
            "epoch  0520 cost =  0.004667633\n",
            "epoch  0521 cost =  0.004693925\n",
            "epoch  0522 cost =  0.004690257\n",
            "epoch  0523 cost =  0.004652191\n",
            "epoch  0524 cost =  0.004226452\n",
            "epoch  0525 cost =  0.004300683\n",
            "epoch  0526 cost =  0.004320420\n",
            "epoch  0527 cost =  0.004280359\n",
            "epoch  0528 cost =  0.004843229\n",
            "epoch  0529 cost =  0.004720870\n",
            "epoch  0530 cost =  0.005594535\n",
            "epoch  0531 cost =  0.005447303\n",
            "epoch  0532 cost =  0.005269958\n",
            "epoch  0533 cost =  0.004974857\n",
            "epoch  0534 cost =  0.004894214\n",
            "epoch  0535 cost =  0.004611895\n",
            "epoch  0536 cost =  0.005104604\n",
            "epoch  0537 cost =  0.004563277\n",
            "epoch  0538 cost =  0.004391365\n",
            "epoch  0539 cost =  0.004534347\n",
            "epoch  0540 cost =  0.004598822\n",
            "epoch  0541 cost =  0.004969820\n",
            "epoch  0542 cost =  0.004326890\n",
            "epoch  0543 cost =  0.004288470\n",
            "epoch  0544 cost =  0.004105861\n",
            "epoch  0545 cost =  0.004212250\n",
            "epoch  0546 cost =  0.004265607\n",
            "epoch  0547 cost =  0.004215258\n",
            "epoch  0548 cost =  0.003942781\n",
            "epoch  0549 cost =  0.004204370\n",
            "epoch  0550 cost =  0.004593720\n",
            "epoch  0551 cost =  0.004616301\n",
            "epoch  0552 cost =  0.005048616\n",
            "epoch  0553 cost =  0.004691962\n",
            "epoch  0554 cost =  0.004631851\n",
            "epoch  0555 cost =  0.005027432\n",
            "epoch  0556 cost =  0.005612521\n",
            "epoch  0557 cost =  0.005375456\n",
            "epoch  0558 cost =  0.005620089\n",
            "epoch  0559 cost =  0.004600686\n",
            "epoch  0560 cost =  0.004322884\n",
            "epoch  0561 cost =  0.004110423\n",
            "epoch  0562 cost =  0.004374955\n",
            "epoch  0563 cost =  0.005051925\n",
            "epoch  0564 cost =  0.005319912\n",
            "epoch  0565 cost =  0.004551032\n",
            "epoch  0566 cost =  0.004622384\n",
            "epoch  0567 cost =  0.005038633\n",
            "epoch  0568 cost =  0.004347351\n",
            "epoch  0569 cost =  0.004458307\n",
            "epoch  0570 cost =  0.004054307\n",
            "epoch  0571 cost =  0.004215840\n",
            "epoch  0572 cost =  0.004117854\n",
            "epoch  0573 cost =  0.003799815\n",
            "epoch  0574 cost =  0.003985122\n",
            "epoch  0575 cost =  0.004040080\n",
            "epoch  0576 cost =  0.004083935\n",
            "epoch  0577 cost =  0.004409891\n",
            "epoch  0578 cost =  0.004140142\n",
            "epoch  0579 cost =  0.004289269\n",
            "epoch  0580 cost =  0.004037272\n",
            "epoch  0581 cost =  0.004067062\n",
            "epoch  0582 cost =  0.004456033\n",
            "epoch  0583 cost =  0.004525199\n",
            "epoch  0584 cost =  0.004558901\n",
            "epoch  0585 cost =  0.004398346\n",
            "epoch  0586 cost =  0.004529831\n",
            "epoch  0587 cost =  0.004295882\n",
            "epoch  0588 cost =  0.004245587\n",
            "epoch  0589 cost =  0.005217938\n",
            "epoch  0590 cost =  0.005881893\n",
            "epoch  0591 cost =  0.004525937\n",
            "epoch  0592 cost =  0.004097622\n",
            "epoch  0593 cost =  0.004280291\n",
            "epoch  0594 cost =  0.004197465\n",
            "epoch  0595 cost =  0.003996765\n",
            "epoch  0596 cost =  0.004207538\n",
            "epoch  0597 cost =  0.005491967\n",
            "epoch  0598 cost =  0.006586298\n",
            "epoch  0599 cost =  0.007833376\n",
            "epoch  0600 cost =  0.007059702\n",
            "epoch  0601 cost =  0.005465196\n",
            "epoch  0602 cost =  0.005369327\n",
            "epoch  0603 cost =  0.004355403\n",
            "epoch  0604 cost =  0.004864716\n",
            "epoch  0605 cost =  0.004285683\n",
            "epoch  0606 cost =  0.004175160\n",
            "epoch  0607 cost =  0.003945886\n",
            "epoch  0608 cost =  0.003920112\n",
            "epoch  0609 cost =  0.003969196\n",
            "epoch  0610 cost =  0.003758306\n",
            "epoch  0611 cost =  0.003864397\n",
            "epoch  0612 cost =  0.003870635\n",
            "epoch  0613 cost =  0.003903215\n",
            "epoch  0614 cost =  0.004892558\n",
            "epoch  0615 cost =  0.005317419\n",
            "epoch  0616 cost =  0.006057489\n",
            "epoch  0617 cost =  0.004848956\n",
            "epoch  0618 cost =  0.004122976\n",
            "epoch  0619 cost =  0.004188086\n",
            "epoch  0620 cost =  0.003949613\n",
            "epoch  0621 cost =  0.004140669\n",
            "epoch  0622 cost =  0.004192271\n",
            "epoch  0623 cost =  0.003707547\n",
            "epoch  0624 cost =  0.003657579\n",
            "epoch  0625 cost =  0.003715571\n",
            "epoch  0626 cost =  0.003925194\n",
            "epoch  0627 cost =  0.003766629\n",
            "epoch  0628 cost =  0.003781255\n",
            "epoch  0629 cost =  0.003892387\n",
            "epoch  0630 cost =  0.004240777\n",
            "epoch  0631 cost =  0.004161141\n",
            "epoch  0632 cost =  0.004609629\n",
            "epoch  0633 cost =  0.005080902\n",
            "epoch  0634 cost =  0.003862509\n",
            "epoch  0635 cost =  0.004004225\n",
            "epoch  0636 cost =  0.004034116\n",
            "epoch  0637 cost =  0.003777308\n",
            "epoch  0638 cost =  0.003837327\n",
            "epoch  0639 cost =  0.004321374\n",
            "epoch  0640 cost =  0.004407426\n",
            "epoch  0641 cost =  0.004701011\n",
            "epoch  0642 cost =  0.004365379\n",
            "epoch  0643 cost =  0.004143053\n",
            "epoch  0644 cost =  0.003932904\n",
            "epoch  0645 cost =  0.004110099\n",
            "epoch  0646 cost =  0.004097536\n",
            "epoch  0647 cost =  0.004931503\n",
            "epoch  0648 cost =  0.005070960\n",
            "epoch  0649 cost =  0.004981781\n",
            "epoch  0650 cost =  0.005410979\n",
            "epoch  0651 cost =  0.004943626\n",
            "epoch  0652 cost =  0.006928278\n",
            "epoch  0653 cost =  0.006596947\n",
            "epoch  0654 cost =  0.005447074\n",
            "epoch  0655 cost =  0.004161636\n",
            "epoch  0656 cost =  0.003870925\n",
            "epoch  0657 cost =  0.003673917\n",
            "epoch  0658 cost =  0.004040211\n",
            "epoch  0659 cost =  0.004008612\n",
            "epoch  0660 cost =  0.003595954\n",
            "epoch  0661 cost =  0.003947457\n",
            "epoch  0662 cost =  0.004069092\n",
            "epoch  0663 cost =  0.003511444\n",
            "epoch  0664 cost =  0.003411943\n",
            "epoch  0665 cost =  0.003696221\n",
            "epoch  0666 cost =  0.003941061\n",
            "epoch  0667 cost =  0.003826829\n",
            "epoch  0668 cost =  0.003976467\n",
            "epoch  0669 cost =  0.003970707\n",
            "epoch  0670 cost =  0.003594646\n",
            "epoch  0671 cost =  0.003893360\n",
            "epoch  0672 cost =  0.003789947\n",
            "epoch  0673 cost =  0.004151193\n",
            "epoch  0674 cost =  0.003706485\n",
            "epoch  0675 cost =  0.003418382\n",
            "epoch  0676 cost =  0.004495124\n",
            "epoch  0677 cost =  0.003856610\n",
            "epoch  0678 cost =  0.004284726\n",
            "epoch  0679 cost =  0.004764760\n",
            "epoch  0680 cost =  0.004718221\n",
            "epoch  0681 cost =  0.003899106\n",
            "epoch  0682 cost =  0.003728582\n",
            "epoch  0683 cost =  0.003587670\n",
            "epoch  0684 cost =  0.003619325\n",
            "epoch  0685 cost =  0.004592187\n",
            "epoch  0686 cost =  0.004837350\n",
            "epoch  0687 cost =  0.004140915\n",
            "epoch  0688 cost =  0.003541379\n",
            "epoch  0689 cost =  0.004260878\n",
            "epoch  0690 cost =  0.004071431\n",
            "epoch  0691 cost =  0.004037472\n",
            "epoch  0692 cost =  0.003908498\n",
            "epoch  0693 cost =  0.003718372\n",
            "epoch  0694 cost =  0.003510873\n",
            "epoch  0695 cost =  0.003627880\n",
            "epoch  0696 cost =  0.003497942\n",
            "epoch  0697 cost =  0.003555656\n",
            "epoch  0698 cost =  0.003590718\n",
            "epoch  0699 cost =  0.003615080\n",
            "epoch  0700 cost =  0.003521791\n",
            "Learning finished..!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljxFfhoUtA3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  x_test = test.iloc[:,1:7]\n",
        "  x_test = np.array(x_test)\n",
        "\n",
        "  x_test = torch.from_numpy(x_test).float().to(device)\n",
        "\n",
        "  prediction = model(x_test)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td47VhZGtHSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = prediction.cpu().numpy().reshape(-1,1)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDvNqC70tLn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAKE = pd.read_csv('Solar_TestData_2.csv', header = None, skiprows= 1) "
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iIS594stN2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "71d7b487-f3ea-447b-e658-80d6f5d0a6c0"
      },
      "source": [
        "submit = pd.read_csv('Solar_SubmitForm_2.csv')\n",
        "submit"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YYYY/MM/DD</th>\n",
              "      <th>Predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0000-00-00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    YYYY/MM/DD  Predict\n",
              "0   0000-00-00      NaN\n",
              "1   0000-00-00      NaN\n",
              "2   0000-00-00      NaN\n",
              "3   0000-00-00      NaN\n",
              "4   0000-00-00      NaN\n",
              "5   0000-00-00      NaN\n",
              "6   0000-00-00      NaN\n",
              "7   0000-00-00      NaN\n",
              "8   0000-00-00      NaN\n",
              "9   0000-00-00      NaN\n",
              "10  0000-00-00      NaN\n",
              "11  0000-00-00      NaN\n",
              "12  0000-00-00      NaN\n",
              "13  0000-00-00      NaN\n",
              "14  0000-00-00      NaN\n",
              "15  0000-00-00      NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ienWkD6wtQg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "0e3256ac-6e4d-40bb-95e0-43abe0c21354"
      },
      "source": [
        "for i in range(len(correct_prediction)):\n",
        "  submit['Predict'][i] = correct_prediction[i].item()\n",
        "\n",
        "submit['YYYY/MM/DD'] = MAKE[0]\n",
        "submit"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YYYY/MM/DD</th>\n",
              "      <th>Predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-11</td>\n",
              "      <td>1.332763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>0.828759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-03-04</td>\n",
              "      <td>0.481010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-03-28</td>\n",
              "      <td>1.786313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-04-27</td>\n",
              "      <td>1.983369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2018-05-11</td>\n",
              "      <td>2.054989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2018-05-30</td>\n",
              "      <td>1.638779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2018-06-12</td>\n",
              "      <td>0.682130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2018-06-25</td>\n",
              "      <td>1.790077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2018-07-28</td>\n",
              "      <td>1.293471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2018-08-16</td>\n",
              "      <td>0.757948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2018-09-14</td>\n",
              "      <td>0.316238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2018-09-25</td>\n",
              "      <td>1.744521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2018-10-22</td>\n",
              "      <td>0.998078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2018-11-15</td>\n",
              "      <td>1.204567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2018-12-07</td>\n",
              "      <td>0.978990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    YYYY/MM/DD   Predict\n",
              "0   2018-01-11  1.332763\n",
              "1   2018-02-16  0.828759\n",
              "2   2018-03-04  0.481010\n",
              "3   2018-03-28  1.786313\n",
              "4   2018-04-27  1.983369\n",
              "5   2018-05-11  2.054989\n",
              "6   2018-05-30  1.638779\n",
              "7   2018-06-12  0.682130\n",
              "8   2018-06-25  1.790077\n",
              "9   2018-07-28  1.293471\n",
              "10  2018-08-16  0.757948\n",
              "11  2018-09-14  0.316238\n",
              "12  2018-09-25  1.744521\n",
              "13  2018-10-22  0.998078\n",
              "14  2018-11-15  1.204567\n",
              "15  2018-12-07  0.978990"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7jsVCtbtUF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit.to_csv('result.csv', mode='w', index = False)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atPMgwuQtW3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8291e803-15b1-4315-d673-ddaac8d333ae"
      },
      "source": [
        "! kaggle competitions submit -c solarenergy-meteorologicalphenomenon2 -f result.csv -m \"14010974 이기택\""
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 498/498 [00:05<00:00, 93.0B/s]\n",
            "Successfully submitted to SejongAI.텀프로젝트.[기상현상에 따른 태양광발전량 예측]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
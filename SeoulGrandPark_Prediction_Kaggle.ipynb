{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeoulGrandPark_Prediction_Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNp31SBmYohFyzxjkK68S5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeGitaek/Kaggle_Solving/blob/master/SeoulGrandPark_Prediction_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk7sxNkO974V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "e30fa157-24bc-4bfd-c15e-90a2a6fac730"
      },
      "source": [
        "!pip uninstall --y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.1.1\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=92dbdfa26e6999c822a9409399b371d89890ea4f3a28b07b1ec4863fdfc6c46a\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_hKsQHr-a0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "200f548e-6f58-4885-858e-3c7cdeb8826f"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!ls -lha kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 68 Jun 28 06:01 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl201_90-cl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0cb11262-d98e-458a-8387-305fd8d3f315"
      },
      "source": [
        "!kaggle competitions download -c 2020-ai-termproject-18011817"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 2020-ai-termproject-18011817.zip to /content\n",
            "\r  0% 0.00/10.5k [00:00<?, ?B/s]\n",
            "\r100% 10.5k/10.5k [00:00<00:00, 8.63MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5_cqTUkhlEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "217431e1-aac1-477d-dc49-7bfe7344a45f"
      },
      "source": [
        "!unzip 2020-ai-termproject-18011817.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  2020-ai-termproject-18011817.zip\n",
            "  inflating: submit_sample.csv       \n",
            "  inflating: test_seoul_grandpark.csv  \n",
            "  inflating: train_seoul_grandpark.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQaEnCZb_k2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyTxbcPs_9Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "torch.manual_seed(777)\n",
        "random.seed(777)\n",
        "torch.cuda.manual_seed_all(777)\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_epochs = 5000\n",
        "batch_size = 100"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtvJ2rjxAAos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d8521c3-58cd-4e44-e8a2-25d4e70fc096"
      },
      "source": [
        "xy_train = pd.read_csv('train_seoul_grandpark.csv', header = None, skiprows=1, usecols=range(1, 8))\n",
        "\n",
        "x_data = xy_train.iloc[: , 1:-1]\n",
        "y_data = xy_train.iloc[: , [-1]]\n",
        "\n",
        "x_data = np.array(x_data)\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_data = scaler.fit_transform(x_data)\n",
        "\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([636, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQn6gxNACRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "data_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size, \n",
        "                                           shuffle = True, \n",
        "                                           drop_last = True)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQLtKYGhLyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MishFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x = ctx.saved_variables[0]\n",
        "        sigmoid = torch.sigmoid(x)\n",
        "        tanh_sp = torch.tanh(F.softplus(x)) \n",
        "        return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return MishFunction.apply(x)\n",
        "\n",
        "def to_Mish(model):\n",
        "    for child_name, child in model.named_children():\n",
        "        if isinstance(child, nn.ReLU):\n",
        "            setattr(model, child_name, Mish())\n",
        "        else:\n",
        "            to_Mish(child)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z3sGsOKAEQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear1 = torch.nn.Linear(5, 8,bias=True)\n",
        "linear2 = torch.nn.Linear(8, 8,bias=True)\n",
        "linear3 = torch.nn.Linear(8, 8,bias=True)\n",
        "linear4 = torch.nn.Linear(8, 8,bias=True)\n",
        "linear5 = torch.nn.Linear(8, 1,bias=True)\n",
        "#dropout = torch.nn.Dropout(p=drop_prob)\n",
        "mish = Mish()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jINDPXbeAGE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.init.kaiming_normal_(linear1.weight)\n",
        "torch.nn.init.kaiming_normal_(linear2.weight)\n",
        "torch.nn.init.kaiming_normal_(linear3.weight)\n",
        "torch.nn.init.kaiming_normal_(linear4.weight)\n",
        "torch.nn.init.kaiming_normal_(linear5.weight)\n",
        "\n",
        "model = torch.nn.Sequential(linear1,mish,\n",
        "                            linear2,mish,\n",
        "                            linear3,mish,\n",
        "                            linear4,mish,\n",
        "                            linear5).to(device)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMVXorkNAJap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "e91b08a3-68f3-42ae-f1f3-9195714c20c5"
      },
      "source": [
        "loss = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "losses = []\n",
        "model_history = []\n",
        "err_history = []\n",
        "\n",
        "total_batch = len(data_loader)\n",
        "\n",
        "for epoch in range(training_epochs + 1):\n",
        "  avg_cost = 0\n",
        "  #model.train()\n",
        "  \n",
        "  for X, Y in data_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "    cost = loss(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "    \n",
        "  model_history.append(model)\n",
        "  err_history.append(avg_cost)\n",
        "  \n",
        "  if epoch % 100 == 0:  \n",
        "    print('Epoch:', '%d' % (epoch + 1), 'Cost =', '{:.9f}'.format(avg_cost))\n",
        "  losses.append(cost.item())\n",
        "print('Learning finished')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Cost = 107983696.000000000\n",
            "Epoch: 101 Cost = 48140944.000000000\n",
            "Epoch: 201 Cost = 40604264.000000000\n",
            "Epoch: 301 Cost = 38773612.000000000\n",
            "Epoch: 401 Cost = 39574460.000000000\n",
            "Epoch: 501 Cost = 39615208.000000000\n",
            "Epoch: 601 Cost = 36950244.000000000\n",
            "Epoch: 701 Cost = 40165628.000000000\n",
            "Epoch: 801 Cost = 38875604.000000000\n",
            "Epoch: 901 Cost = 39880316.000000000\n",
            "Epoch: 1001 Cost = 40449148.000000000\n",
            "Epoch: 1101 Cost = 41269708.000000000\n",
            "Epoch: 1201 Cost = 40066040.000000000\n",
            "Epoch: 1301 Cost = 40332416.000000000\n",
            "Epoch: 1401 Cost = 39766912.000000000\n",
            "Epoch: 1501 Cost = 38269304.000000000\n",
            "Epoch: 1601 Cost = 39625404.000000000\n",
            "Epoch: 1701 Cost = 39999212.000000000\n",
            "Epoch: 1801 Cost = 40118288.000000000\n",
            "Epoch: 1901 Cost = 39769528.000000000\n",
            "Epoch: 2001 Cost = 40260092.000000000\n",
            "Epoch: 2101 Cost = 39938396.000000000\n",
            "Epoch: 2201 Cost = 40292960.000000000\n",
            "Epoch: 2301 Cost = 39942452.000000000\n",
            "Epoch: 2401 Cost = 39867656.000000000\n",
            "Epoch: 2501 Cost = 37567544.000000000\n",
            "Epoch: 2601 Cost = 40108616.000000000\n",
            "Epoch: 2701 Cost = 39717896.000000000\n",
            "Epoch: 2801 Cost = 39635276.000000000\n",
            "Epoch: 2901 Cost = 39753456.000000000\n",
            "Epoch: 3001 Cost = 38300204.000000000\n",
            "Epoch: 3101 Cost = 40165260.000000000\n",
            "Epoch: 3201 Cost = 39180056.000000000\n",
            "Epoch: 3301 Cost = 39829596.000000000\n",
            "Epoch: 3401 Cost = 39738764.000000000\n",
            "Epoch: 3501 Cost = 38864984.000000000\n",
            "Epoch: 3601 Cost = 38103088.000000000\n",
            "Epoch: 3701 Cost = 38158392.000000000\n",
            "Epoch: 3801 Cost = 39386744.000000000\n",
            "Epoch: 3901 Cost = 39062672.000000000\n",
            "Epoch: 4001 Cost = 37875660.000000000\n",
            "Epoch: 4101 Cost = 37555084.000000000\n",
            "Epoch: 4201 Cost = 37823000.000000000\n",
            "Epoch: 4301 Cost = 37989028.000000000\n",
            "Epoch: 4401 Cost = 38735092.000000000\n",
            "Epoch: 4501 Cost = 38705468.000000000\n",
            "Epoch: 4601 Cost = 37826336.000000000\n",
            "Epoch: 4701 Cost = 37658004.000000000\n",
            "Epoch: 4801 Cost = 35838552.000000000\n",
            "Epoch: 4901 Cost = 37870576.000000000\n",
            "Epoch: 5001 Cost = 38853340.000000000\n",
            "Learning finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcnl0HQiAMMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = model_history[np.argmin(err_history)]"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EeYK3yFAOBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xy_test = pd.read_csv('test_seoul_grandpark.csv', header = None, skiprows=1, usecols = range(1, 7))\n",
        "x_data = xy_test.iloc[:, 1:]\n",
        "x_data = np.array(x_data)\n",
        "x_data = scaler.transform(x_data)\n",
        "x_test = torch.FloatTensor(x_data).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()     \n",
        "    predict = best_model(x_test)\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKpHUf59ARiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "163b242e-9610-445c-dc8c-b98e886e0046"
      },
      "source": [
        "submit = pd.read_csv('submit_sample.csv')\n",
        "submit['Expected'] = submit['Expected'].astype(float)\n",
        "for i in range(len(predict)):\n",
        "  submit['Expected'][i] = predict[i]\n",
        "submit.to_csv('submit.csv', mode = 'w', index = False, header = True)\n",
        "submit"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20170330</td>\n",
              "      <td>9434.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20180418</td>\n",
              "      <td>8279.458984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20190430</td>\n",
              "      <td>14760.791992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20180618</td>\n",
              "      <td>10350.997070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20160329</td>\n",
              "      <td>9403.028320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20170424</td>\n",
              "      <td>14475.183594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20180719</td>\n",
              "      <td>3818.627686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20170828</td>\n",
              "      <td>9298.170898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20180227</td>\n",
              "      <td>3713.683105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20160211</td>\n",
              "      <td>4209.882324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20170511</td>\n",
              "      <td>13150.780273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20190301</td>\n",
              "      <td>4235.610840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20161126</td>\n",
              "      <td>1836.839600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20160505</td>\n",
              "      <td>19964.158203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20160727</td>\n",
              "      <td>2930.296387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>20180913</td>\n",
              "      <td>9939.326172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20170714</td>\n",
              "      <td>2578.694336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>20180607</td>\n",
              "      <td>12265.669922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20171218</td>\n",
              "      <td>2473.942383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20171111</td>\n",
              "      <td>5537.188965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20190125</td>\n",
              "      <td>2340.392822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20170621</td>\n",
              "      <td>9332.332031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>20170929</td>\n",
              "      <td>20178.339844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20181224</td>\n",
              "      <td>1974.213745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>20181103</td>\n",
              "      <td>10985.657227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>20170611</td>\n",
              "      <td>18138.681641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>20180917</td>\n",
              "      <td>11864.355469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>20160430</td>\n",
              "      <td>14792.800781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>20170512</td>\n",
              "      <td>9874.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>20190217</td>\n",
              "      <td>2030.024902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id      Expected\n",
              "0   20170330   9434.703125\n",
              "1   20180418   8279.458984\n",
              "2   20190430  14760.791992\n",
              "3   20180618  10350.997070\n",
              "4   20160329   9403.028320\n",
              "5   20170424  14475.183594\n",
              "6   20180719   3818.627686\n",
              "7   20170828   9298.170898\n",
              "8   20180227   3713.683105\n",
              "9   20160211   4209.882324\n",
              "10  20170511  13150.780273\n",
              "11  20190301   4235.610840\n",
              "12  20161126   1836.839600\n",
              "13  20160505  19964.158203\n",
              "14  20160727   2930.296387\n",
              "15  20180913   9939.326172\n",
              "16  20170714   2578.694336\n",
              "17  20180607  12265.669922\n",
              "18  20171218   2473.942383\n",
              "19  20171111   5537.188965\n",
              "20  20190125   2340.392822\n",
              "21  20170621   9332.332031\n",
              "22  20170929  20178.339844\n",
              "23  20181224   1974.213745\n",
              "24  20181103  10985.657227\n",
              "25  20170611  18138.681641\n",
              "26  20180917  11864.355469\n",
              "27  20160430  14792.800781\n",
              "28  20170512   9874.750000\n",
              "29  20190217   2030.024902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85qi7gzmBbNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "47999397-22d6-4362-b42e-f8c9e61e5d12"
      },
      "source": [
        "!kaggle competitions submit -c 2020-ai-termproject-18011817 -f submit.csv -m \"14010974_이기택\""
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 761/761 [00:03<00:00, 194B/s]\n",
            "Successfully submitted to SejongAI.텀프로젝트.[서울대공원 입장객 수 예측]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeoulGrandPark_Prediction_Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5lklZQtm6RGxLpztr4IOQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeGitaek/Kaggle_Solving/blob/master/SeoulGrandPark_Prediction_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk7sxNkO974V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "4791884c-a2d4-43b1-af11-0b4e62921f79"
      },
      "source": [
        "!pip uninstall --y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 8.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.1.1\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=de450d173eca239a82a1e609525563a8d94b071fa3181bd4cb666413afb26773\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_hKsQHr-a0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fdddb22-b355-4d2d-d473-03de9db64f49"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!ls -lha kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 68 Jun 28 13:35 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl201_90-cl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "683ec527-aa9f-4558-8925-11cb7b0b7492"
      },
      "source": [
        "!kaggle competitions download -c 2020-ai-termproject-18011817"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test_seoul_grandpark.csv to /content\n",
            "  0% 0.00/1.14k [00:00<?, ?B/s]\n",
            "100% 1.14k/1.14k [00:00<00:00, 1.95MB/s]\n",
            "Downloading submit_sample.csv to /content\n",
            "  0% 0.00/466 [00:00<?, ?B/s]\n",
            "100% 466/466 [00:00<00:00, 467kB/s]\n",
            "Downloading train_seoul_grandpark.csv to /content\n",
            "  0% 0.00/24.3k [00:00<?, ?B/s]\n",
            "100% 24.3k/24.3k [00:00<00:00, 20.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5_cqTUkhlEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e872f4cd-3e97-4b04-c10a-791d9048de7c"
      },
      "source": [
        "!unzip 2020-ai-termproject-18011817.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open 2020-ai-termproject-18011817.zip, 2020-ai-termproject-18011817.zip.zip or 2020-ai-termproject-18011817.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQaEnCZb_k2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyTxbcPs_9Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "torch.manual_seed(777)\n",
        "random.seed(777)\n",
        "torch.cuda.manual_seed_all(777)\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_epochs = 6000\n",
        "batch_size = 60"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtvJ2rjxAAos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38aa2ef3-9c88-4e28-f97f-700e247cc3a2"
      },
      "source": [
        "xy_train = pd.read_csv('train_seoul_grandpark.csv', header = None, skiprows=1, usecols=range(1, 8))\n",
        "\n",
        "x_data = xy_train.iloc[: , 1:-1]\n",
        "y_data = xy_train.iloc[: , [-1]]\n",
        "\n",
        "x_data = np.array(x_data)\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_data = scaler.fit_transform(x_data)\n",
        "\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([636, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQn6gxNACRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "data_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size, \n",
        "                                           shuffle = True, \n",
        "                                           drop_last = True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQLtKYGhLyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MishFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x = ctx.saved_variables[0]\n",
        "        sigmoid = torch.sigmoid(x)\n",
        "        tanh_sp = torch.tanh(F.softplus(x)) \n",
        "        return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return MishFunction.apply(x)\n",
        "\n",
        "def to_Mish(model):\n",
        "    for child_name, child in model.named_children():\n",
        "        if isinstance(child, nn.ReLU):\n",
        "            setattr(model, child_name, Mish())\n",
        "        else:\n",
        "            to_Mish(child)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z3sGsOKAEQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear1 = torch.nn.Linear(5, 8,bias=True)\n",
        "linear2 = torch.nn.Linear(8, 8,bias=True)\n",
        "linear3 = torch.nn.Linear(8, 8,bias=True)\n",
        "linear4 = torch.nn.Linear(8, 8,bias=True)\n",
        "linear5 = torch.nn.Linear(8, 1,bias=True)\n",
        "#dropout = torch.nn.Dropout(p=drop_prob)\n",
        "mish = Mish()"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jINDPXbeAGE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.init.kaiming_normal_(linear1.weight)\n",
        "torch.nn.init.kaiming_normal_(linear2.weight)\n",
        "torch.nn.init.kaiming_normal_(linear3.weight)\n",
        "torch.nn.init.kaiming_normal_(linear4.weight)\n",
        "torch.nn.init.kaiming_normal_(linear5.weight)\n",
        "\n",
        "model = torch.nn.Sequential(linear1,mish,\n",
        "                            linear2,mish,\n",
        "                            linear3,mish,\n",
        "                            linear4,mish,\n",
        "                            linear5).to(device)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMVXorkNAJap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e5452fd-67cb-4393-e127-dea80c809f69"
      },
      "source": [
        "loss = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "losses = []\n",
        "model_history = []\n",
        "err_history = []\n",
        "\n",
        "total_batch = len(data_loader)\n",
        "\n",
        "for epoch in range(training_epochs + 1):\n",
        "  avg_cost = 0\n",
        "  #model.train()\n",
        "  \n",
        "  for X, Y in data_loader:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "    cost = loss(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / total_batch\n",
        "    \n",
        "  model_history.append(model)\n",
        "  err_history.append(avg_cost)\n",
        "  \n",
        "  if epoch % 100 == 0:  \n",
        "    print('Epoch:', '%d' % (epoch + 1), 'Cost =', '{:.9f}'.format(avg_cost))\n",
        "  losses.append(cost.item())\n",
        "print('Learning finished')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Cost = 107973360.000000000\n",
            "Epoch: 101 Cost = 43472636.000000000\n",
            "Epoch: 201 Cost = 40194460.000000000\n",
            "Epoch: 301 Cost = 38392648.000000000\n",
            "Epoch: 401 Cost = 39578184.000000000\n",
            "Epoch: 501 Cost = 39945072.000000000\n",
            "Epoch: 601 Cost = 36810400.000000000\n",
            "Epoch: 701 Cost = 39775176.000000000\n",
            "Epoch: 801 Cost = 38688892.000000000\n",
            "Epoch: 901 Cost = 40333216.000000000\n",
            "Epoch: 1001 Cost = 40380856.000000000\n",
            "Epoch: 1101 Cost = 40210608.000000000\n",
            "Epoch: 1201 Cost = 39921696.000000000\n",
            "Epoch: 1301 Cost = 40546184.000000000\n",
            "Epoch: 1401 Cost = 39746612.000000000\n",
            "Epoch: 1501 Cost = 38492456.000000000\n",
            "Epoch: 1601 Cost = 39579224.000000000\n",
            "Epoch: 1701 Cost = 39822792.000000000\n",
            "Epoch: 1801 Cost = 39722976.000000000\n",
            "Epoch: 1901 Cost = 39232804.000000000\n",
            "Epoch: 2001 Cost = 39697800.000000000\n",
            "Epoch: 2101 Cost = 39273824.000000000\n",
            "Epoch: 2201 Cost = 39372388.000000000\n",
            "Epoch: 2301 Cost = 38928664.000000000\n",
            "Epoch: 2401 Cost = 38656204.000000000\n",
            "Epoch: 2501 Cost = 36084328.000000000\n",
            "Epoch: 2601 Cost = 38104948.000000000\n",
            "Epoch: 2701 Cost = 37207548.000000000\n",
            "Epoch: 2801 Cost = 38024744.000000000\n",
            "Epoch: 2901 Cost = 37263504.000000000\n",
            "Epoch: 3001 Cost = 35771660.000000000\n",
            "Epoch: 3101 Cost = 37957760.000000000\n",
            "Epoch: 3201 Cost = 36539120.000000000\n",
            "Epoch: 3301 Cost = 37374680.000000000\n",
            "Epoch: 3401 Cost = 37187164.000000000\n",
            "Epoch: 3501 Cost = 36113680.000000000\n",
            "Epoch: 3601 Cost = 35364696.000000000\n",
            "Epoch: 3701 Cost = 34969304.000000000\n",
            "Epoch: 3801 Cost = 36005268.000000000\n",
            "Epoch: 3901 Cost = 35602544.000000000\n",
            "Epoch: 4001 Cost = 34636596.000000000\n",
            "Epoch: 4101 Cost = 34815752.000000000\n",
            "Epoch: 4201 Cost = 34414976.000000000\n",
            "Epoch: 4301 Cost = 35868372.000000000\n",
            "Epoch: 4401 Cost = 35482000.000000000\n",
            "Epoch: 4501 Cost = 34972036.000000000\n",
            "Epoch: 4601 Cost = 34553680.000000000\n",
            "Epoch: 4701 Cost = 34676624.000000000\n",
            "Epoch: 4801 Cost = 32582292.000000000\n",
            "Epoch: 4901 Cost = 34695328.000000000\n",
            "Epoch: 5001 Cost = 34973224.000000000\n",
            "Epoch: 5101 Cost = 34895768.000000000\n",
            "Epoch: 5201 Cost = 34764316.000000000\n",
            "Epoch: 5301 Cost = 34956644.000000000\n",
            "Epoch: 5401 Cost = 33132756.000000000\n",
            "Epoch: 5501 Cost = 34869216.000000000\n",
            "Epoch: 5601 Cost = 34358120.000000000\n",
            "Epoch: 5701 Cost = 32930110.000000000\n",
            "Epoch: 5801 Cost = 33783120.000000000\n",
            "Epoch: 5901 Cost = 32855108.000000000\n",
            "Epoch: 6001 Cost = 33957500.000000000\n",
            "Learning finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcnl0HQiAMMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = model_history[np.argmin(err_history)]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EeYK3yFAOBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xy_test = pd.read_csv('test_seoul_grandpark.csv', header = None, skiprows=1, usecols = range(1, 7))\n",
        "x_data = xy_test.iloc[:, 1:]\n",
        "x_data = np.array(x_data)\n",
        "x_data = scaler.transform(x_data)\n",
        "x_test = torch.FloatTensor(x_data).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()     \n",
        "    predict = best_model(x_test)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKpHUf59ARiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2cc2d99-30e4-493a-84de-44e86b080216"
      },
      "source": [
        "submit = pd.read_csv('submit_sample.csv')\n",
        "submit['Expected'] = submit['Expected'].astype(float)\n",
        "for i in range(len(predict)):\n",
        "  submit['Expected'][i] = predict[i]\n",
        "submit.to_csv('submit.csv', mode = 'w', index = False, header = True)\n",
        "submit"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20170330</td>\n",
              "      <td>12076.124023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20180418</td>\n",
              "      <td>4057.726074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20190430</td>\n",
              "      <td>12156.786133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20180618</td>\n",
              "      <td>10112.790039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20160329</td>\n",
              "      <td>11896.807617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20170424</td>\n",
              "      <td>13943.920898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20180719</td>\n",
              "      <td>3280.721680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20170828</td>\n",
              "      <td>19003.154297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20180227</td>\n",
              "      <td>2930.058105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20160211</td>\n",
              "      <td>4641.748535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20170511</td>\n",
              "      <td>14225.962891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20190301</td>\n",
              "      <td>5655.088379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20161126</td>\n",
              "      <td>471.192841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20160505</td>\n",
              "      <td>27464.589844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20160727</td>\n",
              "      <td>3577.856445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>20180913</td>\n",
              "      <td>8771.451172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20170714</td>\n",
              "      <td>3502.148926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>20180607</td>\n",
              "      <td>10171.592773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20171218</td>\n",
              "      <td>1443.235840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20171111</td>\n",
              "      <td>4721.398926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20190125</td>\n",
              "      <td>3078.712402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20170621</td>\n",
              "      <td>9490.918945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>20170929</td>\n",
              "      <td>20458.019531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20181224</td>\n",
              "      <td>2322.161621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>20181103</td>\n",
              "      <td>13514.588867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>20170611</td>\n",
              "      <td>17344.865234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>20180917</td>\n",
              "      <td>10238.225586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>20160430</td>\n",
              "      <td>19118.804688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>20170512</td>\n",
              "      <td>7462.758789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>20190217</td>\n",
              "      <td>1879.985840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id      Expected\n",
              "0   20170330  12076.124023\n",
              "1   20180418   4057.726074\n",
              "2   20190430  12156.786133\n",
              "3   20180618  10112.790039\n",
              "4   20160329  11896.807617\n",
              "5   20170424  13943.920898\n",
              "6   20180719   3280.721680\n",
              "7   20170828  19003.154297\n",
              "8   20180227   2930.058105\n",
              "9   20160211   4641.748535\n",
              "10  20170511  14225.962891\n",
              "11  20190301   5655.088379\n",
              "12  20161126    471.192841\n",
              "13  20160505  27464.589844\n",
              "14  20160727   3577.856445\n",
              "15  20180913   8771.451172\n",
              "16  20170714   3502.148926\n",
              "17  20180607  10171.592773\n",
              "18  20171218   1443.235840\n",
              "19  20171111   4721.398926\n",
              "20  20190125   3078.712402\n",
              "21  20170621   9490.918945\n",
              "22  20170929  20458.019531\n",
              "23  20181224   2322.161621\n",
              "24  20181103  13514.588867\n",
              "25  20170611  17344.865234\n",
              "26  20180917  10238.225586\n",
              "27  20160430  19118.804688\n",
              "28  20170512   7462.758789\n",
              "29  20190217   1879.985840"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85qi7gzmBbNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37965112-7ae7-45bd-a874-c223864c0131"
      },
      "source": [
        "!kaggle competitions submit -c 2020-ai-termproject-18011817 -f submit.csv -m \"14010974_이기택\""
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 777/777 [00:06<00:00, 112B/s]\n",
            "Successfully submitted to SejongAI.텀프로젝트.[서울대공원 입장객 수 예측]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}